{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naver.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#li 요소 태그에 class 명이 \"realtime_item\"인 요소를 lists에 저장\n",
    "lists = bs.find_all('li', {'class': 'nav_item'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메일\n",
      "카페\n",
      "블로그\n",
      "지식iN\n",
      "쇼핑\n",
      "Pay\n",
      "TV\n",
      "사전\n",
      "뉴스\n",
      "증권\n",
      "부동산\n",
      "지도\n",
      "영화\n",
      "뮤직\n",
      "책\n",
      "웹툰\n"
     ]
    }
   ],
   "source": [
    "for li in lists:\n",
    "    print(li.find('a').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.daum.net')\n",
    "bs = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = bs.find_all('ul', {'class': 'list_favorsch'})\n",
    "lists2 = bs.find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생활 속 거리두기\n",
      "김호중 일정변경\n",
      "제주도숙소\n",
      "윤두준 솔로\n",
      "예쁜명함디자인\n",
      "코로나19 발생현황\n",
      "싹쓰리 해외차트\n",
      "여주환판매\n",
      "유엔군 참전의날\n",
      "크릴오일가격\n",
      "이시언 출연확정\n",
      "김비오 사면\n",
      "스팀다리미거치대\n",
      "인순이 시구\n",
      "파이프행거\n"
     ]
    }
   ],
   "source": [
    "for li in lists:\n",
    "    lists2 = li.find_all('li')\n",
    "    for li2 in lists2:\n",
    "        print(li2.find('a').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html.parser과 lxml파서 라이브러리 비교\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def time_function(f):\n",
    "    '''함수 측정 시간을 측정하기 위한 테코레이터\n",
    "    Args\n",
    "        f (function)\n",
    "    Return \n",
    "        function : 함수 포인터\n",
    "    '''\n",
    "    \n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = f(*args, **kwargs)\n",
    "        end_time = time.time() - start_time\n",
    "        print('{} {} time: {}'.format(f.__name__, args[1], end_time))\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "url = 'https://www.naver.com'\n",
    "\n",
    "@time_function\n",
    "def r_find_all(url, parser):\n",
    "    '''뷰티퓰숲의 find_all 함수를 사용해서 파싱\n",
    "    Args\n",
    "        url (str) : 접속 URL\n",
    "        parser(string) : 뷰피풀숲 내부에서 사용할 파서 이름 (html.parser, lxml)\n",
    "    \n",
    "    Returns\n",
    "        list: 파싱 결과 리스트\n",
    "    '''\n",
    "    r = requests.get(url)\n",
    "    bs = BeautifulSoup(r.text, parser)\n",
    "    lists = bs.find_all('li', {'class':'nav_item'})\n",
    "    titles = []\n",
    "    for li in lists:\n",
    "        title = li.find('a').text\n",
    "        titles.append(title)\n",
    "    return titles\n",
    "\n",
    "@time_function\n",
    "def r_selector(url, parser):\n",
    "    \"\"\"뷰티풀숲의 select 함수를 사용해서 파시\n",
    "    Args\n",
    "        url (str)\n",
    "    \n",
    "    Returns \n",
    "        list: 파싱 결과 리스트\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    bs = BeautifulSoup(r.text, parser)\n",
    "    lists = bs.select('li.nav_item > a')\n",
    "    for li in lists:\n",
    "        print(li.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_find_all html.parser time: 0.6397581100463867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['메일',\n",
       " '카페',\n",
       " '블로그',\n",
       " '지식iN',\n",
       " '쇼핑',\n",
       " 'Pay',\n",
       " 'TV',\n",
       " '사전',\n",
       " '뉴스',\n",
       " '증권',\n",
       " '부동산',\n",
       " '지도',\n",
       " '영화',\n",
       " '뮤직',\n",
       " '책',\n",
       " '웹툰']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_find_all(url, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_find_all lxml time: 0.4105069637298584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['메일',\n",
       " '카페',\n",
       " '블로그',\n",
       " '지식iN',\n",
       " '쇼핑',\n",
       " 'Pay',\n",
       " 'TV',\n",
       " '사전',\n",
       " '뉴스',\n",
       " '증권',\n",
       " '부동산',\n",
       " '지도',\n",
       " '영화',\n",
       " '뮤직',\n",
       " '책',\n",
       " '웹툰']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_find_all(url, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메일\n",
      "카페\n",
      "블로그\n",
      "지식iN\n",
      "쇼핑\n",
      "Pay\n",
      "TV\n",
      "사전\n",
      "뉴스\n",
      "증권\n",
      "부동산\n",
      "지도\n",
      "영화\n",
      "뮤직\n",
      "책\n",
      "웹툰\n",
      "r_selector lxml time: 0.43367934226989746\n"
     ]
    }
   ],
   "source": [
    "r_selector(url, 'lxml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
